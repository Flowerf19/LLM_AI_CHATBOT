import discord
import os
import aiofiles
import asyncio
import logging
from typing import Dict, List, Optional
import json

logger = logging.getLogger(__name__)

from discord.ext import commands
# Extension setup function for discord.py
async def setup(bot: commands.Bot):
    # Th√™m Cog th·ª±c thi v√†o bot
    await bot.add_cog(SummaryServiceCog(bot))
    logger.info("‚úÖ SummaryServiceCog loaded and extension setup called")

# ƒê·ªãnh nghƒ©a Cog cho bot
class SummaryServiceCog(commands.Cog):
    def __init__(self, bot):
        self.bot = bot
        # C√≥ th·ªÉ kh·ªüi t·∫°o c√°c service ph·ª• ·ªü ƒë√¢y n·∫øu c·∫ßn

    # ƒê·∫£m b·∫£o kh√¥ng c√≥ h√†m on_message listener ·ªü ƒë√¢y ƒë·ªÉ tr√°nh duplicate responses

    # X√ìA L·ªÜNH PING N·∫æU C√ì

class SummaryService:
    def _clean_summary_text(self, text: str) -> str:
        """Lo·∫°i b·ªè escape, markdown, k√Ω t·ª± th·ª´a kh·ªèi summary text."""
        import re
        if not text:
            return ""
        # Xo√° code block markdown
        text = re.sub(r"```[\s\S]*?```", "", text)
        # Xo√° d·∫•u ngo·∫∑c k√©p th·ª´a
        text = text.replace('"', "")
        # Xo√° c√°c k√Ω t·ª± escape \n, \\n+        text = text.replace('\\n', '\n').replace('\\', '')
        # Xo√° c√°c ƒëo·∫°n JSON ho·∫∑c d·∫•u ngo·∫∑c th·ª´a
        text = re.sub(r'\{.*?\}', '', text, flags=re.DOTALL)
        # Xo√° kho·∫£ng tr·∫Øng th·ª´a
        text = re.sub(r'\n+', '\n', text)
        text = text.strip()
        return text
    def _parse_summary_fields(self, summary_text: str) -> dict:
        """Parse summary text th√†nh dict c√°c tr∆∞·ªùng ch√≠nh (theo format chu·∫©n)."""
        import re
        fields = [
            ("T√™n", r"T√™n:\s*(.*)"),
            ("Tu·ªïi", r"Tu·ªïi:\s*(.*)"),
            ("Sinh nh·∫≠t", r"Sinh nh·∫≠t:\s*(.*)"),
            ("C√¥ng ngh·ªá", r"C√¥ng ngh·ªá:\s*(.*)"),
            ("Gi·∫£i tr√≠", r"Gi·∫£i tr√≠:\s*(.*)"),
            ("Kh√°c", r"Kh√°c:\s*(.*)"),
            ("Giao ti·∫øp", r"Giao ti·∫øp:\s*(.*)"),
            ("T√¢m tr·∫°ng", r"T√¢m tr·∫°ng:\s*(.*)"),
            ("ƒê·∫∑c ƒëi·ªÉm", r"ƒê·∫∑c ƒëi·ªÉm:\s*(.*)"),
            ("B·∫°n b√®", r"B·∫°n b√®:\s*(.*)"),
            ("Gia ƒë√¨nh", r"Gia ƒë√¨nh:\s*(.*)"),
            ("ƒê·ªìng nghi·ªáp", r"ƒê·ªìng nghi·ªáp:\s*(.*)"),
            ("Ng∆∞·ªùi quan tr·ªçng", r"Ng∆∞·ªùi quan tr·ªçng:\s*(.*)"),
            ("Ghi ch√∫ v·ªÅ t∆∞∆°ng t√°c", r"Ghi ch√∫ v·ªÅ t∆∞∆°ng t√°c:\s*(.*)"),
            ("Ch·ªß ƒë·ªÅ ƒë√£ th·∫£o lu·∫≠n", r"Ch·ªß ƒë·ªÅ ƒë√£ th·∫£o lu·∫≠n:\s*(.*)"),
            ("M·ª©c ƒë·ªô th√¢n thi·∫øt", r"M·ª©c ƒë·ªô th√¢n thi·∫øt:\s*(.*)"),
            ("Ghi ch√∫ ƒë·∫∑c bi·ªát", r"Ghi ch√∫ ƒë·∫∑c bi·ªát:\s*(.*)"),
            ("Hi·ªán t·∫°i", r"Hi·ªán t·∫°i:\s*(.*)"),
            ("K·∫ø ho·∫°ch", r"K·∫ø ho·∫°ch:\s*(.*)")
        ]
        result = {}
        for key, pattern in fields:
            m = re.search(pattern, summary_text)
            if m:
                result[key] = m.group(1).strip()
            else:
                result[key] = None
        return result

    def _merge_summary_fields(self, old_summary: str, new_summary: str) -> str:
        """Ch·ªâ c·∫≠p nh·∫≠t tr∆∞·ªùng c√≥ th√¥ng tin m·ªõi, gi·ªØ l·∫°i tr∆∞·ªùng c≈© n·∫øu tr∆∞·ªùng m·ªõi r·ªóng ho·∫∑c 'Kh√¥ng c√≥'."""
        import re
        import os
        # L√†m s·∫°ch text tr∆∞·ªõc khi parse
        old_clean = self._clean_summary_text(old_summary or "")
        new_clean = self._clean_summary_text(new_summary or "")
        old_fields = self._parse_summary_fields(old_clean)
        new_fields = self._parse_summary_fields(new_clean)
        # N·∫øu tr∆∞·ªùng m·ªõi r·ªóng ho·∫∑c 'Kh√¥ng c√≥' th√¨ gi·ªØ tr∆∞·ªùng c≈©
        merged = {}
        for k in old_fields:
            v_new = new_fields.get(k, None)
            if v_new and v_new.lower() != "kh√¥ng c√≥":
                merged[k] = v_new
            else:
                merged[k] = old_fields.get(k, "Kh√¥ng c√≥")
        # Load template format t·ª´ file
        try:
            base_dir = os.path.dirname(os.path.abspath(__file__))
            src_dir = os.path.dirname(os.path.dirname(base_dir))
            format_path = os.path.join(src_dir, 'data', 'prompts', 'summary_format.txt')
            with open(format_path, 'r', encoding='utf-8') as f:
                template = f.read()
            # Format template v·ªõi merged dict
            return template.format(**merged)
        except Exception as e:
            logger.error(f"Error loading or formatting summary template: {e}")
            # Fallback v·ªÅ format c·ª©ng n·∫øu l·ªói
            lines = []
            lines.append("=== TH√îNG TIN C∆† B·∫¢N ===")
            lines.append(f"T√™n: {merged['T√™n']}")
            lines.append(f"Tu·ªïi: {merged['Tu·ªïi']}")
            lines.append(f"Sinh nh·∫≠t: {merged['Sinh nh·∫≠t']}")
            lines.append("=== S·ªû TH√çCH & ƒêAM M√ä ===")
            lines.append(f"‚Ä¢ C√¥ng ngh·ªá: {merged['C√¥ng ngh·ªá']}")
            lines.append(f"‚Ä¢ Gi·∫£i tr√≠: {merged['Gi·∫£i tr√≠']}")
            lines.append(f"‚Ä¢ Kh√°c: {merged['Kh√°c']}")
            lines.append("=== T√çNH C√ÅCH & PHONG C√ÅCH ===")
            lines.append(f"‚Ä¢ Giao ti·∫øp: {merged['Giao ti·∫øp']}")
            lines.append(f"‚Ä¢ T√¢m tr·∫°ng: {merged['T√¢m tr·∫°ng']}")
            lines.append(f"‚Ä¢ ƒê·∫∑c ƒëi·ªÉm: {merged['ƒê·∫∑c ƒëi·ªÉm']}")
            lines.append("=== M·ªêI QUAN H·ªÜ V·ªöI NG∆Ø·ªúI KH√ÅC ===")
            lines.append(f"‚Ä¢ B·∫°n b√®: {merged['B·∫°n b√®']}")
            lines.append(f"‚Ä¢ Gia ƒë√¨nh: {merged['Gia ƒë√¨nh']}")
            lines.append(f"‚Ä¢ ƒê·ªìng nghi·ªáp: {merged['ƒê·ªìng nghi·ªáp']}")
            lines.append(f"‚Ä¢ Ng∆∞·ªùi quan tr·ªçng: {merged['Ng∆∞·ªùi quan tr·ªçng']}")
            lines.append(f"‚Ä¢ Ghi ch√∫ v·ªÅ t∆∞∆°ng t√°c: {merged['Ghi ch√∫ v·ªÅ t∆∞∆°ng t√°c']}")
            lines.append("=== L·ªäCH S·ª¨ T∆Ø∆†NG T√ÅC ===")
            lines.append(f"‚Ä¢ Ch·ªß ƒë·ªÅ ƒë√£ th·∫£o lu·∫≠n: {merged['Ch·ªß ƒë·ªÅ ƒë√£ th·∫£o lu·∫≠n']}")
            lines.append(f"‚Ä¢ M·ª©c ƒë·ªô th√¢n thi·∫øt: {merged['M·ª©c ƒë·ªô th√¢n thi·∫øt']}")
            lines.append(f"‚Ä¢ Ghi ch√∫ ƒë·∫∑c bi·ªát: {merged['Ghi ch√∫ ƒë·∫∑c bi·ªát']}")
            lines.append("=== D·ª∞ √ÅN & M·ª§C TI√äU ===")
            lines.append(f"‚Ä¢ Hi·ªán t·∫°i: {merged['Hi·ªán t·∫°i']}")
            lines.append(f"‚Ä¢ K·∫ø ho·∫°ch: {merged['K·∫ø ho·∫°ch']}")
            return "\n".join(lines)
    def __init__(self, llm_service, prompts_dir: str, config_dir: str):
        self.llm_service = llm_service
        # ƒê·∫£m b·∫£o l∆∞u ƒë√∫ng v√†o src/data/user_summaries
        base_dir = os.path.dirname(os.path.abspath(__file__))  # .../src/services/...
        src_dir = os.path.dirname(os.path.dirname(base_dir))    # .../src
        self.prompts_dir = os.path.join(src_dir, 'data', 'prompts')
        self.config_dir = os.path.join(src_dir, 'data', 'config')
        self.summaries_dir = os.path.join(src_dir, 'data', 'user_summaries')
        
        logger.info(f"üìÅ SummaryService using directory: {self.summaries_dir}")
        
        # Ensure directories exist
        os.makedirs(self.summaries_dir, exist_ok=True)
        os.makedirs(self.prompts_dir, exist_ok=True)
        os.makedirs(self.config_dir, exist_ok=True)
        
        # Load important keywords
        self.important_keywords = self._load_important_keywords()
        
        # Tracking for updates
        self._last_update = {}
    
    def _load_important_keywords(self) -> Dict:
        """Load important keywords for summary updates"""
        import json
        # ∆Øu ti√™n file dummy n·∫øu c√≥
        dummy_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'dummy', 'important_keywords.json')
        config_path = os.path.join(self.config_dir, 'important_keywords.json')
        default_keywords = {
            "basic_info": ["t√™n", "tu·ªïi", "sinh", "sinh nh·∫≠t", "ng√†y sinh"],
            "hobbies": ["th√≠ch", "y√™u", "m√™", "s·ªü th√≠ch", "hobby"],
            "emotions": ["bu·ªìn", "vui", "stress", "lo", "h·∫°nh ph√∫c", "t√¢m tr·∫°ng"],
            "relationships": ["ƒë·ªôc th√¢n", "ng∆∞·ªùi y√™u", "b·∫°n g√°i", "b·∫°n trai"],
            "dreams": ["mu·ªën", "∆∞·ªõc", "d·ª± ƒë·ªãnh", "k·∫ø ho·∫°ch", "m∆° ∆∞·ªõc"],
            "changes": ["kh√¥ng th√≠ch", "b·ªè", "gi·ªù th√≠ch", "chuy·ªÉn sang", "chia tay", "c√≥ ng∆∞·ªùi y√™u"]
        }
        for path in [dummy_path, config_path]:
            if os.path.exists(path):
                try:
                    with open(path, 'r', encoding='utf-8') as f:
                        logger.info(f"Loaded important_keywords from: {path}")
                        return json.load(f)
                except Exception as e:
                    logger.error(f"Error loading important_keywords from {path}: {e}")
        logger.warning("No important_keywords.json found, using default keywords.")
        return default_keywords
    
    def get_user_history(self, user_id: str) -> List[Dict]:
        """FIXED: Get user conversation history v·ªõi absolute path"""
        history_file = os.path.join(self.summaries_dir, f"{user_id}_history.json")
        
        logger.debug(f"üîç Looking for history file: {history_file}")
        logger.debug(f"üîç SummaryService summaries_dir: {self.summaries_dir}")
        logger.debug(f"üîç File exists: {os.path.exists(history_file)}")
        
        # Check if file exists with absolute path
        if not os.path.exists(history_file):
            logger.info(f"üìù History file not found: {history_file}")
            return []
        
        try:
            # Check file size first
            file_size = os.path.getsize(history_file)
            logger.debug(f"üìÑ History file size: {file_size} bytes")
            
            if file_size == 0:
                logger.warning(f"üìù History file is empty: {history_file}")
                return []
            
            with open(history_file, 'r', encoding='utf-8') as f:
                content = f.read()
                logger.debug(f"üìÑ Raw file content length: {len(content)} chars")
                
                if not content.strip():
                    logger.warning(f"üìù History file has no content: {history_file}")
                    return []
                
                # Parse JSON
                history = json.loads(content)
                
                if not isinstance(history, list):
                    logger.error(f"üìù History file format invalid (not a list): {history_file}")
                    return []
                
                logger.info(f"‚úÖ Successfully loaded {len(history)} messages for user {user_id}")
                return history
                
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå JSON decode error for {user_id}: {e}")
            logger.error(f"‚ùå File content preview: {content[:200] if 'content' in locals() else 'N/A'}")
            return []
        except Exception as e:
            logger.error(f"‚ùå Error loading history for {user_id}: {e}")
            return []
    
    def get_user_summary(self, user_id: str) -> str:
        """Get user summary v·ªõi absolute path v√† better caching"""
        summary_file = os.path.join(self.summaries_dir, f"{user_id}_summary.txt")
        
        if not os.path.exists(summary_file):
            logger.debug(f"üìù Summary file not found: {summary_file}")
            return ""
        
        try:
            with open(summary_file, 'r', encoding='utf-8') as f:
                content = f.read().strip()
                
            if content and len(content) > 10:
                logger.debug(f"üìñ Loaded summary for {user_id}: {len(content)} chars")
                return content
            else:
                logger.debug(f"üìù Empty summary for {user_id}")
                return ""
                
        except Exception as e:
            logger.error(f"Error loading summary for {user_id}: {e}")
            return ""
    
    def save_user_summary(self, user_id: str, summary: str):
        """Save user summary v·ªõi absolute path"""
        import json
        summary_file = os.path.join(self.summaries_dir, f"{user_id}_summary.txt")
        try:
            # Ensure directory exists
            os.makedirs(os.path.dirname(summary_file), exist_ok=True)
            # N·∫øu summary l√† dict, chuy·ªÉn th√†nh text
            if isinstance(summary, dict):
                summary = json.dumps(summary, ensure_ascii=False, indent=2)
            with open(summary_file, 'w', encoding='utf-8') as f:
                f.write(summary.strip())
            logger.info(f"üìù Summary saved for user {user_id} at: {summary_file}")
        except Exception as e:
            logger.error(f"Error saving summary for {user_id}: {e}")
    
    def should_update_summary(self, user_id: str, message_content: str, current_summary: str) -> bool:
        """REALTIME: Enhanced check for immediate summary updates"""
        message_lower = message_content.lower()
        
        # FORCE UPDATE cho template summary
        if self._is_template_summary(current_summary):
            logger.info(f"üîÑ Template summary detected for {user_id} - FORCE UPDATE")
            return True
        
        # Check for important keywords
        for category, keywords in self.important_keywords.items():
            for keyword in keywords:
                if keyword in message_lower:
                    logger.info(f"Important keyword '{keyword}' found in message from {user_id}")
                    return True
        
        # REALTIME: TƒÉng t·∫ßn su·∫•t update
        import random
        return random.random() < 0.3  # TƒÉng t·ª´ 10% l√™n 30%

    def _is_template_summary(self, summary: str) -> bool:
        """Check if summary is a template (has [Kh√¥ng c√≥] entries)"""
        if not summary:
            return True
        
        template_indicators = [
            "[Kh√¥ng c√≥]",
            "T√™n: [Kh√¥ng c√≥]",
            "Tu·ªïi: [Kh√¥ng c√≥]",
            "S·ªü th√≠ch: [Kh√¥ng c√≥]"
        ]
        
        # N·∫øu c√≥ >= 2 template indicators ‚Üí l√† template
        count = sum(1 for indicator in template_indicators if indicator in summary)
        
        if count >= 2:
            logger.info(f"üîç Template summary detected ({count} indicators)")
            return True
        
        return False

    async def update_summary_smart(self, user_id: str, message_content: Optional[str] = None) -> Optional[str]:
        """REALTIME: Force update ƒë·ªÉ ƒë·∫£m b·∫£o summary ƒë∆∞·ª£c c·∫≠p nh·∫≠t ngay, t·ªëi ∆∞u logic c·∫≠p nh·∫≠t."""
        import json
        try:
            logger.info(f"üîÑ Starting REALTIME summary update for user {user_id}")
            history = self.get_user_history(user_id)
            logger.info(f"üìä History stats for user {user_id}: {len(history)} total messages")
            if len(history) < 1:
                logger.info(f"üìù User {user_id}: Not enough messages ({len(history)}/1) for summary")
                self._last_update[user_id] = 0
                return None
            user_messages = [msg for msg in history if msg.get('role') == 'user']
            unique_content = set(msg.get('content', '').strip().lower() for msg in user_messages)
            total_chars = sum(len(msg.get('content', '')) for msg in user_messages)
            existing_summary = self.get_user_summary(user_id)
            is_template = self._is_template_summary(existing_summary)
            current_msg_count = len(history)
            last_update_count = self._last_update.get(user_id, 0)
            # ∆Øu ti√™n update n·∫øu l√† template ho·∫∑c c√≥ t·ª´ kh√≥a quan tr·ªçng ho·∫∑c c√≥ tin nh·∫Øn m·ªõi
            should_update = False
            if is_template:
                logger.info(f"üîÑ TEMPLATE DETECTED for user {user_id}: Force updating...")
                should_update = True
            elif message_content and self.should_update_summary(user_id, message_content, existing_summary):
                logger.info(f"üîÑ Important keyword or change detected for user {user_id}: Updating...")
                should_update = True
            elif current_msg_count - last_update_count >= 1:
                should_update = True
            # N·∫øu kh√¥ng ƒë·ªß ƒëa d·∫°ng ho·∫∑c qu√° ng·∫Øn, ch·ªâ cho update n·∫øu l√† template ho·∫∑c c√≥ t·ª´ kh√≥a quan tr·ªçng
            if (len(unique_content) < 1 or total_chars < 10) and not (is_template or (message_content and self.should_update_summary(user_id, message_content, existing_summary))):
                logger.info(f"üìù User {user_id}: Not enough diverse/long content for summary")
                self._last_update[user_id] = last_update_count
                return None
            if not should_update:
                logger.debug(f"üìù User {user_id}: No update needed (msg_count: {current_msg_count}, last: {last_update_count})")
                return existing_summary
            # Chu·∫©n b·ªã d·ªØ li·ªáu h·ªôi tho·∫°i
            recent_history = history[-20:]
            conversation_text = "\n".join([
                f"{msg['role']}: {msg['content']}"
                for msg in recent_history if msg.get('content')
            ])
            logger.info(f"üìù User {user_id}: Generating summary from {len(recent_history)} recent messages")
            summary_prompt_template = self._load_summary_prompt()
            summary_prompt = f"""{summary_prompt_template}

QUAN TR·ªåNG: T·∫°o summary ho√†n to√†n m·ªõi d·ª±a tr√™n cu·ªôc h·ªôi tho·∫°i th·ª±c t·∫ø.
KH√îNG s·ª≠ d·ª•ng "[Kh√¥ng c√≥]" - ch·ªâ ghi th√¥ng tin c√≥ th·∫≠t.

Cu·ªôc h·ªôi tho·∫°i c·∫ßn ph√¢n t√≠ch:
{conversation_text}

H√£y t·∫°o t√≥m t·∫Øt chi ti·∫øt v√† ch√≠nh x√°c:"""
            logger.info(f"ü§ñ Sending REALTIME summary request to LLM for user {user_id}")
            new_summary = await self.llm_service.generate_response(summary_prompt, user_id)
            if not new_summary or len(new_summary.strip()) < 15:
                logger.warning(f"‚ö†Ô∏è Generated summary too short for user {user_id}: '{new_summary}'")
                return existing_summary if not is_template else None
            # N·∫øu LLM tr·∫£ v·ªÅ JSON, t·ª± ƒë·ªông chuy·ªÉn sang text format chu·∫©n
            try:
                parsed = json.loads(new_summary)
                if isinstance(parsed, dict):
                    logger.info(f"üìù LLM returned JSON, converting to text format for summary.")
                    # Chuy·ªÉn dict sang text format chu·∫©n b·∫±ng _merge_summary_fields
                    new_summary = self._merge_summary_fields(existing_summary, json.dumps(parsed, ensure_ascii=False))
            except Exception:
                pass  # Kh√¥ng ph·∫£i JSON, gi·ªØ nguy√™n
            if self._is_template_summary(new_summary):
                logger.warning(f"‚ö†Ô∏è Generated summary is still template-like for user {user_id}")
                return existing_summary if not is_template else None
            merged_summary = self._merge_summary_fields(existing_summary, new_summary.strip())
            self.save_user_summary(user_id, merged_summary)
            self._last_update[user_id] = len(history)
            logger.info(f"‚úÖ REALTIME Summary updated for user {user_id} ({len(history)} total messages)")
            logger.info(f"üìÑ New summary preview: {merged_summary[:100]}...")
            return merged_summary
        except Exception as e:
            logger.error(f"‚ùå Error updating summary for {user_id}: {e}", exc_info=True)
            self._last_update[user_id] = 0
            return None
    
    def _load_summary_prompt(self) -> str:
        """Load summary prompt from file"""
        prompt_file = os.path.join(self.prompts_dir, 'summary_prompt.txt')
        
        if not os.path.exists(prompt_file):
            return "Ph√¢n t√≠ch cu·ªôc h·ªôi tho·∫°i v√† t·∫°o t√≥m t·∫Øt th√¥ng tin ng∆∞·ªùi d√πng."
        
        try:
            with open(prompt_file, 'r', encoding='utf-8') as f:
                return f.read().strip()
        except Exception as e:
            logger.error(f"Error loading summary prompt: {e}")
            return "Ph√¢n t√≠ch cu·ªôc h·ªôi tho·∫°i v√† t·∫°o t√≥m t·∫Øt th√¥ng tin ng∆∞·ªùi d√πng."
    
    def clear_user_summary(self, user_id: str):
        """Clear user summary"""
        summary_file = os.path.join(self.summaries_dir, f"{user_id}_summary.txt")
        
        if os.path.exists(summary_file):
            try:
                os.remove(summary_file)
                logger.info(f"Summary cleared for user {user_id}")
            except Exception as e:
                logger.error(f"Error clearing summary for {user_id}: {e}")