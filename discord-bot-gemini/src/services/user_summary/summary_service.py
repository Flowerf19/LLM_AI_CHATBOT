import os
import logging
from typing import Dict, List, Optional
import json
import re
from discord.ext import commands
from config.settings import Config

logger = logging.getLogger(__name__)


# Extension setup function for discord.py
async def setup(bot: commands.Bot):
    # Th√™m Cog th·ª±c thi v√†o bot
    await bot.add_cog(SummaryServiceCog(bot))
    logger.info("‚úÖ SummaryServiceCog loaded and extension setup called")

# ƒê·ªãnh nghƒ©a Cog cho bot
class SummaryServiceCog(commands.Cog):
    def __init__(self, bot):
        self.bot = bot
        # C√≥ th·ªÉ kh·ªüi t·∫°o c√°c service ph·ª• ·ªü ƒë√¢y n·∫øu c·∫ßn

    # ƒê·∫£m b·∫£o kh√¥ng c√≥ h√†m on_message listener ·ªü ƒë√¢y ƒë·ªÉ tr√°nh duplicate responses

    # X√ìA L·ªÜNH PING N·∫æU C√ì

class SummaryService:
    def _clean_summary_text(self, text: str) -> str:
        """Lo·∫°i b·ªè escape, markdown, k√Ω t·ª± th·ª´a kh·ªèi summary text."""

        if not text:
            return ""
        # If the text is valid JSON, return as-is (don't strip JSON content)
        try:
            json.loads(text)
            return text
        except Exception:
            pass
        # Xo√° code block markdown
        text = re.sub(r"```[\s\S]*?```", "", text)
        # Xo√° d·∫•u ngo·∫∑c k√©p th·ª´a (kh√¥ng √°p d·ª•ng cho JSON v√¨ ch√∫ng ƒë√£ ƒë∆∞·ª£c tr·∫£ v·ªÅ ph√≠a tr√™n)
        text = text.replace('"', "")
        # Xo√° c√°c k√Ω t·ª± escape \n, \\n+        text = text.replace('\\n', '\n').replace('\\', '')
        # N·∫øu kh√¥ng ph·∫£i JSON, xo√° c√°c ƒëo·∫°n ngo·∫∑c nh·ªçn/c√∫ ph√°p gi·ªëng JSON (n·∫øu c√≥)
        text = re.sub(r'\{.*?\}', '', text, flags=re.DOTALL)
        # Xo√° kho·∫£ng tr·∫Øng th·ª´a
        text = re.sub(r'\n+', '\n', text)
        text = text.strip()
        return text
    def _parse_summary_fields(self, summary_text: str) -> dict:
        """Parse summary text th√†nh dict c√°c tr∆∞·ªùng ch√≠nh (theo format chu·∫©n)."""
        import re
        import json
        
        # Try parsing as JSON first (for new format)
        try:
            data = json.loads(summary_text)
            flat_data = {}
            
            # Map JSON structure back to internal keys
            if isinstance(data, dict):
                # Basic Info
                basic = data.get("basic_info", {})
                flat_data["T√™n"] = basic.get("name")
                flat_data["Tu·ªïi"] = basic.get("age")
                flat_data["Sinh nh·∫≠t"] = basic.get("birthday")
                
                # Hobbies
                hobbies = data.get("hobbies_and_passion", {})
                flat_data["C√¥ng ngh·ªá"] = hobbies.get("tech")
                flat_data["Gi·∫£i tr√≠"] = hobbies.get("entertainment")
                flat_data["Kh√°c"] = hobbies.get("other")
                
                # Personality
                personality = data.get("personality_and_style", {})
                flat_data["Giao ti·∫øp"] = personality.get("communication")
                flat_data["T√¢m tr·∫°ng"] = personality.get("mood")
                flat_data["ƒê·∫∑c ƒëi·ªÉm"] = personality.get("traits")
                
                # Relationships
                rels = data.get("relationships", {})
                flat_data["B·∫°n b√®"] = rels.get("friends")
                flat_data["Gia ƒë√¨nh"] = rels.get("family")
                flat_data["ƒê·ªìng nghi·ªáp"] = rels.get("colleagues")
                flat_data["Ng∆∞·ªùi quan tr·ªçng"] = rels.get("significant_other")
                flat_data["Ghi ch√∫ v·ªÅ t∆∞∆°ng t√°c"] = rels.get("interaction_notes")
                
                # History
                history = data.get("interaction_history", {})
                flat_data["Ch·ªß ƒë·ªÅ ƒë√£ th·∫£o lu·∫≠n"] = history.get("discussed_topics")
                flat_data["M·ª©c ƒë·ªô th√¢n thi·∫øt"] = history.get("intimacy_level")
                flat_data["Ghi ch√∫ ƒë·∫∑c bi·ªát"] = history.get("special_notes")
                
                # Projects
                projects = data.get("projects_and_goals", {})
                flat_data["Hi·ªán t·∫°i"] = projects.get("current")
                flat_data["K·∫ø ho·∫°ch"] = projects.get("plans")
                
                # Return only non-None values
                return {k: str(v) if v is not None else None for k, v in flat_data.items()}
        except (json.JSONDecodeError, AttributeError):
            pass

        fields = [
            ("T√™n", r"T√™n:\s*(.*)"),
            ("Tu·ªïi", r"Tu·ªïi:\s*(.*)"),
            ("Sinh nh·∫≠t", r"Sinh nh·∫≠t:\s*(.*)"),
            ("C√¥ng ngh·ªá", r"C√¥ng ngh·ªá:\s*(.*)"),
            ("Gi·∫£i tr√≠", r"Gi·∫£i tr√≠:\s*(.*)"),
            ("Kh√°c", r"Kh√°c:\s*(.*)"),
            ("Giao ti·∫øp", r"Giao ti·∫øp:\s*(.*)"),
            ("T√¢m tr·∫°ng", r"T√¢m tr·∫°ng:\s*(.*)"),
            ("ƒê·∫∑c ƒëi·ªÉm", r"ƒê·∫∑c ƒëi·ªÉm:\s*(.*)"),
            ("B·∫°n b√®", r"B·∫°n b√®:\s*(.*)"),
            ("Gia ƒë√¨nh", r"Gia ƒë√¨nh:\s*(.*)"),
            ("ƒê·ªìng nghi·ªáp", r"ƒê·ªìng nghi·ªáp:\s*(.*)"),
            ("Ng∆∞·ªùi quan tr·ªçng", r"Ng∆∞·ªùi quan tr·ªçng:\s*(.*)"),
            ("Ghi ch√∫ v·ªÅ t∆∞∆°ng t√°c", r"Ghi ch√∫ v·ªÅ t∆∞∆°ng t√°c:\s*(.*)"),
            ("Ch·ªß ƒë·ªÅ ƒë√£ th·∫£o lu·∫≠n", r"Ch·ªß ƒë·ªÅ ƒë√£ th·∫£o lu·∫≠n:\s*(.*)"),
            ("M·ª©c ƒë·ªô th√¢n thi·∫øt", r"M·ª©c ƒë·ªô th√¢n thi·∫øt:\s*(.*)"),
            ("Ghi ch√∫ ƒë·∫∑c bi·ªát", r"Ghi ch√∫ ƒë·∫∑c bi·ªát:\s*(.*)"),
            ("Hi·ªán t·∫°i", r"Hi·ªán t·∫°i:\s*(.*)"),
            ("K·∫ø ho·∫°ch", r"K·∫ø ho·∫°ch:\s*(.*)")
        ]
        result = {}
        for key, pattern in fields:
            m = re.search(pattern, summary_text)
            if m:
                result[key] = m.group(1).strip()
            else:
                result[key] = None
        return result

    def _merge_summary_fields(self, old_summary: str, new_summary: str) -> str:
        """Ch·ªâ c·∫≠p nh·∫≠t tr∆∞·ªùng c√≥ th√¥ng tin m·ªõi, gi·ªØ l·∫°i tr∆∞·ªùng c≈© n·∫øu tr∆∞·ªùng m·ªõi r·ªóng ho·∫∑c 'Kh√¥ng c√≥'."""
        # L√†m s·∫°ch text tr∆∞·ªõc khi parse
        old_clean = self._clean_summary_text(old_summary or "")
        new_clean = self._clean_summary_text(new_summary or "")
        old_fields = self._parse_summary_fields(old_clean)
        new_fields = self._parse_summary_fields(new_clean)
        # N·∫øu tr∆∞·ªùng m·ªõi r·ªóng ho·∫∑c 'Kh√¥ng c√≥' th√¨ gi·ªØ tr∆∞·ªùng c≈©
        merged = {}
        for k in old_fields:
            v_new = new_fields.get(k, None)
            if v_new and v_new.lower() != "kh√¥ng c√≥":
                merged[k] = v_new
            else:
                merged[k] = old_fields.get(k, "Kh√¥ng c√≥")
        
        # Load template format t·ª´ file
        try:
            import json
            # Ensure path is correct and handle potential Path/str mismatch
            prompts_dir = getattr(Config, 'PROMPTS_DIR', 'src/data/prompts')
            if isinstance(prompts_dir, str):
                format_path = os.path.join(prompts_dir, 'summary_format.json')
            else:
                format_path = prompts_dir / 'summary_format.json'
                
            with open(format_path, 'r', encoding='utf-8') as f:
                template_data = json.load(f)
            
            # Recursive function to fill template
            def fill_template(data, values):
                if isinstance(data, dict):
                    return {k: fill_template(v, values) for k, v in data.items()}
                elif isinstance(data, list):
                    return [fill_template(item, values) for item in data]
                elif isinstance(data, str):
                    # Check if string is a placeholder like "{Key}"
                    if data.startswith("{") and data.endswith("}"):
                        key = data[1:-1]
                        # Handle None values gracefully
                        val = values.get(key)
                        return val if val is not None else "Kh√¥ng c√≥"
                    return data
                else:
                    return data

            filled_data = fill_template(template_data, merged)
            return json.dumps(filled_data, ensure_ascii=False, indent=2)

        except Exception as e:
            logger.error(f"Error loading or formatting summary template: {e}", exc_info=True)
            # Fallback to simple JSON dump of merged data to avoid reverting to text format
            return json.dumps(merged, ensure_ascii=False, indent=2)
    def __init__(self, llm_service, prompts_dir: str = None, config_dir: str = None):
        self.llm_service = llm_service
        
        self.prompts_dir = Config.PROMPTS_DIR
        self.config_dir = Config.DATA_DIR / 'config'
        self.summaries_dir = Config.USER_SUMMARIES_DIR
        
        logger.info(f"üìÅ SummaryService using directory: {self.summaries_dir}")
        
        # Ensure directories exist
        self.summaries_dir.mkdir(parents=True, exist_ok=True)
        self.prompts_dir.mkdir(parents=True, exist_ok=True)
        self.config_dir.mkdir(parents=True, exist_ok=True)
        
        # Load important keywords
        self.important_keywords = self._load_important_keywords()
        
        # Tracking for updates
        self._last_update = {}
    
    def _load_important_keywords(self) -> Dict:
        """Load important keywords for summary updates"""
        import json
        config_path = os.path.join(self.config_dir, 'important_keywords.json')
        
        if os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    logger.info(f"Loaded important_keywords from: {config_path}")
                    return json.load(f)
            except Exception as e:
                logger.error(f"Error loading important_keywords from {config_path}: {e}")
                
        logger.warning("No important_keywords.json found. Summary updates will rely on random chance.")
        return {}
    
    def get_user_history(self, user_id: str) -> List[Dict]:
        """FIXED: Get user conversation history v·ªõi absolute path"""
        history_file = os.path.join(self.summaries_dir, f"{user_id}_history.json")
        
        logger.debug(f"üîç Looking for history file: {history_file}")
        logger.debug(f"üîç SummaryService summaries_dir: {self.summaries_dir}")
        logger.debug(f"üîç File exists: {os.path.exists(history_file)}")
        
        # Check if file exists with absolute path
        if not os.path.exists(history_file):
            logger.info(f"üìù History file not found: {history_file}")
            return []
        
        try:
            # Check file size first
            file_size = os.path.getsize(history_file)
            logger.debug(f"üìÑ History file size: {file_size} bytes")
            
            if file_size == 0:
                logger.warning(f"üìù History file is empty: {history_file}")
                return []
            
            with open(history_file, 'r', encoding='utf-8') as f:
                content = f.read()
                logger.debug(f"üìÑ Raw file content length: {len(content)} chars")
                
                if not content.strip():
                    logger.warning(f"üìù History file has no content: {history_file}")
                    return []
                
                # Parse JSON
                history = json.loads(content)
                
                if not isinstance(history, list):
                    logger.error(f"üìù History file format invalid (not a list): {history_file}")
                    return []
                
                logger.info(f"‚úÖ Successfully loaded {len(history)} messages for user {user_id}")
                return history
                
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå JSON decode error for {user_id}: {e}")
            logger.error(f"‚ùå File content preview: {content[:200] if 'content' in locals() else 'N/A'}")
            return []
        except Exception as e:
            logger.error(f"‚ùå Error loading history for {user_id}: {e}")
            return []
    
    def get_user_summary(self, user_id: str) -> str:
        """Get user summary v·ªõi absolute path v√† better caching"""
        summary_file = os.path.join(self.summaries_dir, f"{user_id}_summary.json")
        
        content = ""
        if os.path.exists(summary_file):
            try:
                with open(summary_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    content = json.dumps(data, ensure_ascii=False, indent=2)
            except Exception as e:
                logger.error(f"Error loading JSON summary for {user_id}: {e}")
        
        if content and len(content) > 10:
            logger.debug(f"üìñ Loaded summary for {user_id}: {len(content)} chars")
            return content
        else:
            logger.debug(f"üìù Empty summary for {user_id}")
            return ""
    
    def save_user_summary(self, user_id: str, summary: str):
        """Save user summary v·ªõi absolute path"""
        import json
        summary_file = os.path.join(self.summaries_dir, f"{user_id}_summary.json")
        try:
            # Ensure directory exists
            os.makedirs(os.path.dirname(summary_file), exist_ok=True)
            
            # N·∫øu summary l√† string, th·ª≠ parse json
            data = summary
            if isinstance(summary, str):
                try:
                    data = json.loads(summary)
                except Exception:
                    # N·∫øu kh√¥ng ph·∫£i json, gi·ªØ nguy√™n string (cho legacy text format)
                    # Nh∆∞ng t·ªët nh·∫•t l√† convert sang dict n·∫øu c√≥ th·ªÉ
                    pass

            with open(summary_file, 'w', encoding='utf-8') as f:
                if isinstance(data, dict) or isinstance(data, list):
                    json.dump(data, f, ensure_ascii=False, indent=2)
                else:
                    # Fallback for raw text
                    f.write(str(data))
                    
            logger.info(f"üìù Summary saved for user {user_id} at: {summary_file}")
                
        except Exception as e:
            logger.error(f"Error saving summary for {user_id}: {e}")
    
    def should_update_summary(self, user_id: str, message_content: str, current_summary: str) -> bool:
        """REALTIME: Enhanced check for immediate summary updates"""
        message_lower = message_content.lower()
        
        # FORCE UPDATE cho template summary
        if self._is_template_summary(current_summary):
            logger.info(f"üîÑ Template summary detected for {user_id} - FORCE UPDATE")
            return True
        
        # Check for important keywords
        for category, keywords in self.important_keywords.items():
            for keyword in keywords:
                if keyword in message_lower:
                    logger.info(f"Important keyword '{keyword}' found in message from {user_id}")
                    return True
        
        # REALTIME: TƒÉng t·∫ßn su·∫•t update
        import random
        return random.random() < 0.3  # TƒÉng t·ª´ 10% l√™n 30%

    def _is_template_summary(self, summary: str) -> bool:
        """Check if summary is a template (has [Kh√¥ng c√≥] entries)"""
        if not summary:
            return True
        
        template_indicators = [
            "[Kh√¥ng c√≥]",
            "T√™n: [Kh√¥ng c√≥]",
            "Tu·ªïi: [Kh√¥ng c√≥]",
            "S·ªü th√≠ch: [Kh√¥ng c√≥]"
        ]
        
        # N·∫øu c√≥ >= 2 template indicators ‚Üí l√† template
        count = sum(1 for indicator in template_indicators if indicator in summary)
        
        if count >= 2:
            logger.info(f"üîç Template summary detected ({count} indicators)")
            return True
        
        return False

    async def update_summary_smart(self, user_id: str, message_content: Optional[str] = None) -> Optional[str]:
        """REALTIME: Force update ƒë·ªÉ ƒë·∫£m b·∫£o summary ƒë∆∞·ª£c c·∫≠p nh·∫≠t ngay, t·ªëi ∆∞u logic c·∫≠p nh·∫≠t."""
        import json
        try:
            logger.info(f"üîÑ Starting REALTIME summary update for user {user_id}")
            history = self.get_user_history(user_id)
            logger.info(f"üìä History stats for user {user_id}: {len(history)} total messages")
            if len(history) < 1:
                logger.info(f"üìù User {user_id}: Not enough messages ({len(history)}/1) for summary")
                self._last_update[user_id] = 0
                return None
            user_messages = [msg for msg in history if msg.get('role') == 'user']
            unique_content = set(msg.get('content', '').strip().lower() for msg in user_messages)
            total_chars = sum(len(msg.get('content', '')) for msg in user_messages)
            existing_summary = self.get_user_summary(user_id)
            is_template = self._is_template_summary(existing_summary)
            current_msg_count = len(history)
            last_update_count = self._last_update.get(user_id, 0)
            # ∆Øu ti√™n update n·∫øu l√† template ho·∫∑c c√≥ t·ª´ kh√≥a quan tr·ªçng ho·∫∑c c√≥ tin nh·∫Øn m·ªõi
            should_update = False
            if is_template:
                logger.info(f"üîÑ TEMPLATE DETECTED for user {user_id}: Force updating...")
                should_update = True
            elif message_content and self.should_update_summary(user_id, message_content, existing_summary):
                logger.info(f"üîÑ Important keyword or change detected for user {user_id}: Updating...")
                should_update = True
            elif current_msg_count - last_update_count >= 1:
                should_update = True
            # N·∫øu kh√¥ng ƒë·ªß ƒëa d·∫°ng ho·∫∑c qu√° ng·∫Øn, ch·ªâ cho update n·∫øu l√† template ho·∫∑c c√≥ t·ª´ kh√≥a quan tr·ªçng
            if (len(unique_content) < 1 or total_chars < 10) and not (is_template or (message_content and self.should_update_summary(user_id, message_content, existing_summary))):
                logger.info(f"üìù User {user_id}: Not enough diverse/long content for summary")
                self._last_update[user_id] = last_update_count
                return None
            if not should_update:
                logger.debug(f"üìù User {user_id}: No update needed (msg_count: {current_msg_count}, last: {last_update_count})")
                return existing_summary
            # Chu·∫©n b·ªã d·ªØ li·ªáu h·ªôi tho·∫°i
            recent_history = history[-20:]
            conversation_text = "\n".join([
                f"{msg['role']}: {msg['content']}"
                for msg in recent_history if msg.get('content')
            ])
            logger.info(f"üìù User {user_id}: Generating summary from {len(recent_history)} recent messages")
            summary_prompt_template = self._load_summary_prompt()
            summary_prompt = f"""{summary_prompt_template}

QUAN TR·ªåNG: T·∫°o summary ho√†n to√†n m·ªõi d·ª±a tr√™n cu·ªôc h·ªôi tho·∫°i th·ª±c t·∫ø.
KH√îNG s·ª≠ d·ª•ng "[Kh√¥ng c√≥]" - ch·ªâ ghi th√¥ng tin c√≥ th·∫≠t.

Cu·ªôc h·ªôi tho·∫°i c·∫ßn ph√¢n t√≠ch:
{conversation_text}

H√£y t·∫°o t√≥m t·∫Øt chi ti·∫øt v√† ch√≠nh x√°c:"""
            logger.info(f"ü§ñ Sending REALTIME summary request to LLM for user {user_id}")
            new_summary = await self.llm_service.generate_response(summary_prompt, user_id)
            if not new_summary or len(new_summary.strip()) < 15:
                logger.warning(f"‚ö†Ô∏è Generated summary too short for user {user_id}: '{new_summary}'")
                return existing_summary if not is_template else None
            # N·∫øu LLM tr·∫£ v·ªÅ JSON, t·ª± ƒë·ªông chuy·ªÉn sang text format chu·∫©n
            try:
                parsed = json.loads(new_summary)
                if isinstance(parsed, dict):
                    logger.info("üìù LLM returned JSON, converting to text format for summary.")
                    # Chuy·ªÉn dict sang text format chu·∫©n b·∫±ng _merge_summary_fields
                    new_summary = self._merge_summary_fields(existing_summary, json.dumps(parsed, ensure_ascii=False))
            except Exception:
                pass  # Kh√¥ng ph·∫£i JSON, gi·ªØ nguy√™n
            if self._is_template_summary(new_summary):
                logger.warning(f"‚ö†Ô∏è Generated summary is still template-like for user {user_id}")
                return existing_summary if not is_template else None
            merged_summary = self._merge_summary_fields(existing_summary, new_summary.strip())
            self.save_user_summary(user_id, merged_summary)
            self._last_update[user_id] = len(history)
            logger.info(f"‚úÖ REALTIME Summary updated for user {user_id} ({len(history)} total messages)")
            logger.info(f"üìÑ New summary preview: {merged_summary[:100]}...")
            return merged_summary
        except Exception as e:
            logger.error(f"‚ùå Error updating summary for {user_id}: {e}", exc_info=True)
            self._last_update[user_id] = 0
            return None
    
    def _load_summary_prompt(self) -> str:
        """Load summary prompt from file"""
        prompt_file = os.path.join(self.prompts_dir, 'summary_prompt.json')
        
        if not os.path.exists(prompt_file):
            return "Ph√¢n t√≠ch cu·ªôc h·ªôi tho·∫°i v√† t·∫°o t√≥m t·∫Øt th√¥ng tin ng∆∞·ªùi d√πng."
        
        try:
            with open(prompt_file, 'r', encoding='utf-8') as f:
                return f.read().strip()
        except Exception as e:
            logger.error(f"Error loading summary prompt: {e}")
            return "Ph√¢n t√≠ch cu·ªôc h·ªôi tho·∫°i v√† t·∫°o t√≥m t·∫Øt th√¥ng tin ng∆∞·ªùi d√πng."
    
    def clear_user_summary(self, user_id: str):
        """Clear user summary"""
        summary_file = os.path.join(self.summaries_dir, f"{user_id}_summary.txt")
        
        if os.path.exists(summary_file):
            try:
                os.remove(summary_file)
                logger.info(f"Summary cleared for user {user_id}")
            except Exception as e:
                logger.error(f"Error clearing summary for {user_id}: {e}")