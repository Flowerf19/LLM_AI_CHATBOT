import os
import logging
import json
from typing import Callable, Optional, List, Dict

logger = logging.getLogger(__name__)

class SummaryUpdateManager:
    def __init__(self, prompts_dir: Optional[str] = None, config_dir: Optional[str] = None, llm_service=None, summaries_dir: Optional[str] = None):
        # Chuáº©n hÃ³a: LuÃ´n lÆ°u vÃ o src/data cho cÃ¡c file cáº¥u hÃ¬nh vÃ  prompt
        project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        # If explicit prompts_dir or config_dir provided, use it (for testing or custom deployment).
        if prompts_dir:
            self.prompts_dir = prompts_dir
        else:
            self.prompts_dir = os.path.join(project_root, 'data', 'prompts')
        if config_dir:
            self.config_dir = config_dir
        else:
            self.config_dir = os.path.join(project_root, 'data', 'config')
        self.llm_service = llm_service
        # LuÃ´n xÃ¡c Ä‘á»‹nh Ä‘Æ°á»ng dáº«n dá»±a trÃªn vá»‹ trÃ­ file hiá»‡n táº¡i
        if summaries_dir:
            # Use provided summaries_dir directly
            self.summaries_dir = summaries_dir
        else:
            base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
            self.summaries_dir = os.path.join(base_dir, 'data', 'user_summaries')
        self.important_keywords = self._load_important_keywords()
        self._last_update = {}
        # Cho phÃ©p gÃ¡n cÃ¡c hÃ m thao tÃ¡c file tá»« bÃªn ngoÃ i
        self.get_user_history: Optional[Callable[[str], List[Dict]]] = None
        self.get_user_summary: Optional[Callable[[str], str]] = None
        self.save_user_summary: Optional[Callable[[str, str], None]] = None

    def _clean_summary_text(self, text: str) -> str:
        import re
        if not text:
            return ""
        text = re.sub(r"```[\s\S]*?```", "", text)
        text = text.replace('"', "")
        text = text.replace('\\n', '\n').replace('\\', '')
        text = re.sub(r'\{.*?\}', '', text, flags=re.DOTALL)
        text = re.sub(r'\n+', '\n', text)
        return text.strip()

    def _parse_summary_fields(self, summary_text: str) -> dict:
        import re
        fields = [
            ("TÃªn", r"TÃªn:\s*(.*)"),
            ("Tuá»•i", r"Tuá»•i:\s*(.*)"),
            ("Sinh nháº­t", r"Sinh nháº­t:\s*(.*)"),
            ("CÃ´ng nghá»‡", r"CÃ´ng nghá»‡:\s*(.*)"),
            ("Giáº£i trÃ­", r"Giáº£i trÃ­:\s*(.*)"),
            ("KhÃ¡c", r"KhÃ¡c:\s*(.*)"),
            ("Giao tiáº¿p", r"Giao tiáº¿p:\s*(.*)"),
            ("TÃ¢m tráº¡ng", r"TÃ¢m tráº¡ng:\s*(.*)"),
            ("Äáº·c Ä‘iá»ƒm", r"Äáº·c Ä‘iá»ƒm:\s*(.*)"),
            ("Báº¡n bÃ¨", r"Báº¡n bÃ¨:\s*(.*)"),
            ("Gia Ä‘Ã¬nh", r"Gia Ä‘Ã¬nh:\s*(.*)"),
            ("Äá»“ng nghiá»‡p", r"Äá»“ng nghiá»‡p:\s*(.*)"),
            ("NgÆ°á»i quan trá»ng", r"NgÆ°á»i quan trá»ng:\s*(.*)"),
            ("Ghi chÃº vá» tÆ°Æ¡ng tÃ¡c", r"Ghi chÃº vá» tÆ°Æ¡ng tÃ¡c:\s*(.*)"),
            ("Chá»§ Ä‘á» Ä‘Ã£ tháº£o luáº­n", r"Chá»§ Ä‘á» Ä‘Ã£ tháº£o luáº­n:\s*(.*)"),
            ("Má»©c Ä‘á»™ thÃ¢n thiáº¿t", r"Má»©c Ä‘á»™ thÃ¢n thiáº¿t:\s*(.*)"),
            ("Ghi chÃº Ä‘áº·c biá»‡t", r"Ghi chÃº Ä‘áº·c biá»‡t:\s*(.*)"),
            ("Hiá»‡n táº¡i", r"Hiá»‡n táº¡i:\s*(.*)"),
            ("Káº¿ hoáº¡ch", r"Káº¿ hoáº¡ch:\s*(.*)")
        ]
        result = {}
        for key, pattern in fields:
            m = re.search(pattern, summary_text)
            result[key] = m.group(1).strip() if m else None
        return result

    def _merge_summary_fields(self, old_summary: str, new_summary: str) -> str:
        old_clean = self._clean_summary_text(old_summary or "")
        new_clean = self._clean_summary_text(new_summary or "")
        old_fields = self._parse_summary_fields(old_clean)
        new_fields = self._parse_summary_fields(new_clean)
        merged = {}
        for k in old_fields:
            v_new = new_fields.get(k, None)
            # Náº¿u giÃ¡ trá»‹ má»›i há»£p lá»‡ (khÃ´ng pháº£i None, khÃ´ng trá»‘ng, khÃ´ng pháº£i 'KhÃ´ng cÃ³', khÃ¡c giÃ¡ trá»‹ cÅ©) thÃ¬ láº¥y giÃ¡ trá»‹ má»›i
            if v_new and v_new.strip() and v_new.lower() not in ["khÃ´ng cÃ³", "none"] and v_new != old_fields.get(k):
                merged[k] = v_new
            elif v_new and v_new.strip() and v_new.lower() not in ["khÃ´ng cÃ³", "none"]:
                merged[k] = v_new
            else:
                merged[k] = old_fields.get(k, "KhÃ´ng cÃ³")
        lines = []
        lines.append("=== THÃ”NG TIN CÆ  Báº¢N ===")
        lines.append(f"TÃªn: {merged['TÃªn']}")
        lines.append(f"Tuá»•i: {merged['Tuá»•i']}")
        lines.append(f"Sinh nháº­t: {merged['Sinh nháº­t']}")
        lines.append("=== Sá»ž THÃCH & ÄAM MÃŠ ===")
        lines.append(f"â€¢ CÃ´ng nghá»‡: {merged['CÃ´ng nghá»‡']}")
        lines.append(f"â€¢ Giáº£i trÃ­: {merged['Giáº£i trÃ­']}")
        lines.append(f"â€¢ KhÃ¡c: {merged['KhÃ¡c']}")
        lines.append("=== TÃNH CÃCH & PHONG CÃCH ===")
        lines.append(f"â€¢ Giao tiáº¿p: {merged['Giao tiáº¿p']}")
        lines.append(f"â€¢ TÃ¢m tráº¡ng: {merged['TÃ¢m tráº¡ng']}")
        lines.append(f"â€¢ Äáº·c Ä‘iá»ƒm: {merged['Äáº·c Ä‘iá»ƒm']}")
        lines.append("=== Má»I QUAN Há»† Vá»šI NGÆ¯á»œI KHÃC ===")
        lines.append(f"â€¢ Báº¡n bÃ¨: {merged['Báº¡n bÃ¨']}")
        lines.append(f"â€¢ Gia Ä‘Ã¬nh: {merged['Gia Ä‘Ã¬nh']}")
        lines.append(f"â€¢ Äá»“ng nghiá»‡p: {merged['Äá»“ng nghiá»‡p']}")
        lines.append(f"â€¢ NgÆ°á»i quan trá»ng: {merged['NgÆ°á»i quan trá»ng']}")
        lines.append(f"â€¢ Ghi chÃº vá» tÆ°Æ¡ng tÃ¡c: {merged['Ghi chÃº vá» tÆ°Æ¡ng tÃ¡c']}")
        lines.append("=== Lá»ŠCH Sá»¬ TÆ¯Æ NG TÃC ===")
        lines.append(f"â€¢ Chá»§ Ä‘á» Ä‘Ã£ tháº£o luáº­n: {merged['Chá»§ Ä‘á» Ä‘Ã£ tháº£o luáº­n']}")
        lines.append(f"â€¢ Má»©c Ä‘á»™ thÃ¢n thiáº¿t: {merged['Má»©c Ä‘á»™ thÃ¢n thiáº¿t']}")
        lines.append(f"â€¢ Ghi chÃº Ä‘áº·c biá»‡t: {merged['Ghi chÃº Ä‘áº·c biá»‡t']}")
        lines.append("=== Dá»° ÃN & Má»¤C TIÃŠU ===")
        lines.append(f"â€¢ Hiá»‡n táº¡i: {merged['Hiá»‡n táº¡i']}")
        lines.append(f"â€¢ Káº¿ hoáº¡ch: {merged['Káº¿ hoáº¡ch']}")
        return "\n".join(lines)

    def _load_important_keywords(self) -> Dict:
        keywords_file = os.path.join(self.config_dir, 'important_keywords.json')
        default_keywords = {
            "basic_info": ["tÃªn", "tuá»•i", "sinh", "sinh nháº­t", "ngÃ y sinh"],
            "hobbies": ["thÃ­ch", "yÃªu", "mÃª", "sá»Ÿ thÃ­ch", "hobby"],
            "emotions": ["buá»“n", "vui", "stress", "lo", "háº¡nh phÃºc", "tÃ¢m tráº¡ng"],
            "relationships": ["Ä‘á»™c thÃ¢n", "ngÆ°á»i yÃªu", "báº¡n gÃ¡i", "báº¡n trai"],
            "dreams": ["muá»‘n", "Æ°á»›c", "dá»± Ä‘á»‹nh", "káº¿ hoáº¡ch", "mÆ¡ Æ°á»›c"],
            "changes": ["khÃ´ng thÃ­ch", "bá»", "giá» thÃ­ch", "chuyá»ƒn sang", "chia tay", "cÃ³ ngÆ°á»i yÃªu"]
        }
        if not os.path.exists(keywords_file):
            os.makedirs(os.path.dirname(keywords_file), exist_ok=True)
            try:
                with open(keywords_file, 'w', encoding='utf-8') as f:
                    json.dump(default_keywords, f, ensure_ascii=False, indent=2)
                logger.info(f"Created default keywords file: {keywords_file}")
            except Exception as e:
                logger.error(f"Error creating keywords file: {e}")
            return default_keywords
        try:
            with open(keywords_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"Error loading keywords file: {e}")
            return default_keywords

    def _is_template_summary(self, summary: str) -> bool:
        if not summary:
            return True
        template_indicators = [
            "[KhÃ´ng cÃ³]",
            "TÃªn: [KhÃ´ng cÃ³]",
            "Tuá»•i: [KhÃ´ng cÃ³]",
            "Sá»Ÿ thÃ­ch: [KhÃ´ng cÃ³]"
        ]
        count = sum(1 for indicator in template_indicators if indicator in summary)
        if count >= 2:
            logger.info(f"ðŸ” Template summary detected ({count} indicators)")
            return True
        return False

    def should_update_summary(self, user_id: str, message_content: str, current_summary: str) -> bool:
        message_lower = message_content.lower()
        if self._is_template_summary(current_summary):
            logger.info(f"ðŸ”„ Template summary detected for {user_id} - FORCE UPDATE")
            return True
        for category, keywords in self.important_keywords.items():
            for keyword in keywords:
                if keyword in message_lower:
                    logger.info(f"Important keyword '{keyword}' found in message from {user_id}")
                    return True
        import random
        return random.random() < 0.3

    def _load_summary_prompt(self) -> str:
        prompt_file = os.path.join(self.prompts_dir, 'summary_prompt.json')
        if not os.path.exists(prompt_file):
            raise FileNotFoundError(f"Prompt file not found: {prompt_file}")
        with open(prompt_file, 'r', encoding='utf-8') as f:
            return f.read().strip()

    async def update_summary_smart(self, user_id: str, message_content: Optional[str] = None) -> Optional[str]:
        try:
            logger.info(f"ðŸ”„ Starting REALTIME summary update for user {user_id}")
            if not callable(self.get_user_history) or not callable(self.get_user_summary) or not callable(self.save_user_summary):
                raise Exception("SummaryUpdateManager: get_user_history, get_user_summary, save_user_summary must be set before calling update_summary_smart.")
            history = self.get_user_history(user_id)
            if history is None:
                history = []
            logger.info(f"ðŸ“Š History stats for user {user_id}: {len(history)} total messages")
            if len(history) < 2:
                logger.info(f"ðŸ“ User {user_id}: Not enough messages ({len(history)}/2) for summary")
                self._last_update[user_id] = 0
                return None
            user_messages = [msg for msg in history if msg.get('role') == 'user']
            unique_content = set(msg.get('content', '').strip().lower() for msg in user_messages)
            total_chars = sum(len(msg.get('content', '')) for msg in user_messages)
            existing_summary = self.get_user_summary(user_id)
            if existing_summary is None:
                existing_summary = ""
            is_template = self._is_template_summary(existing_summary)
            current_msg_count = len(history)
            last_update_count = self._last_update.get(user_id, 0)
            should_update = False
            if is_template:
                logger.info(f" TEMPLATE DETECTED for user {user_id}: Force updating...")
                should_update = True
            elif message_content and self.should_update_summary(user_id, message_content, existing_summary):
                logger.info(f" Important keyword or change detected for user {user_id}: Updating...")
                should_update = True
            elif current_msg_count - last_update_count >= 1:
                should_update = True
            if (len(unique_content) < 2 or total_chars < 15) and not (is_template or (message_content and self.should_update_summary(user_id, message_content, existing_summary))):
                logger.info(f" User {user_id}: Not enough diverse/long content for summary")
                self._last_update[user_id] = last_update_count
                return None
            if not should_update:
                logger.debug(f"ðŸ“ User {user_id}: No update needed (msg_count: {current_msg_count}, last: {last_update_count})")
                return existing_summary
            recent_history = history[-20:]
            conversation_text = "\n".join([
                f"{msg['role']}: {msg['content']}"
                for msg in recent_history if msg.get('content')
            ])
            logger.info(f"ðŸ“ User {user_id}: Generating summary from {len(recent_history)} recent messages")
            summary_prompt_template = self._load_summary_prompt()
            summary_prompt = f"""{summary_prompt_template}

QUAN TRá»ŒNG: Táº¡o summary hoÃ n toÃ n má»›i dá»±a trÃªn cuá»™c há»™i thoáº¡i thá»±c táº¿.
KHÃ”NG sá»­ dá»¥ng "[KhÃ´ng cÃ³]" - chá»‰ ghi thÃ´ng tin cÃ³ tháº­t.

Cuá»™c há»™i thoáº¡i cáº§n phÃ¢n tÃ­ch:
{conversation_text}

HÃ£y táº¡o tÃ³m táº¯t chi tiáº¿t vÃ  chÃ­nh xÃ¡c:"""
            logger.info(f"ðŸ¤– Sending REALTIME summary request to LLM for user {user_id}")
            new_summary = await self.llm_service.generate_response(summary_prompt, user_id)
            if not new_summary or len(new_summary.strip()) < 15:
                logger.warning(f"âš ï¸ Generated summary too short for user {user_id}: '{new_summary}'")
                return existing_summary if not is_template else None
            if self._is_template_summary(new_summary):
                logger.warning(f"âš ï¸ Generated summary is still template-like for user {user_id}")
                return existing_summary if not is_template else None
            self.save_user_summary(user_id, self._merge_summary_fields(existing_summary, new_summary.strip()))
            self._last_update[user_id] = len(history)
            logger.info(f"âœ… REALTIME Summary updated for user {user_id} ({len(history)} total messages)")
            logger.info(f"ðŸ“„ New summary preview: {new_summary.strip()[:100]}...")
            return new_summary.strip()
        except Exception as e:
            logger.error(f"âŒ Error updating summary for {user_id}: {e}", exc_info=True)
            self._last_update[user_id] = 0
            return None 